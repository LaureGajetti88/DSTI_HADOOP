Dans la même idée que le lab sur hadoop, ici nous allons nous interesser à quelques commandes introductive du langage YARN.
Le tp nous étant fourni, nous avons dejà les intallations pour l'emploi du modul yarn

1. Il nous faut trouver se module pour s'y connecter :
a) connexion au serveur client apache :
$ ssh laure.gajetti-dsti@edge1.au.adaltas.cloud
+ mdp
b) Rechercher le module yarn = faire une recherche en linux : 
$ find / -name hadoop-mapreduce-examples*.jar

2. La question est de se placer dans le repertoire :
$ cd /usr/hdp/3.1.0.0-78/hadoop-mapreduce/

3. Lancer le job :
$ yarn jar hadoop-mapreduce-examples.jar pi 10 100

TP sur Yarn et la notion de map-reduce : 
1. Creer un script python pour executer la fonction map : map.py
$ vi map.py
copier le script :
#!/usr/bin/env python
"""map.py"""

import sys

# input comes from STDIN (standard input)
for line in sys.stdin:
    # remove leading and trailing whitespace
    line = line.strip()
    # split the line into words
    words = line.split()
    # increase counters
    for word in words:
        # write the results to STDOUT (standard output);
        # what we output here will be the input for the
        # Reduce step, i.e. the input for reducer.py
        #
        # tab-delimited; the trivial word count is 1
        print '%s\t%s' % (word, 1)
        
Attention a bien respecter l'indentation
Verifions que la fonction map est correct :
$cat 2701-0.txt | /home/laure.gajetti-dsti/map.py

Après un map il faut obligatoirement ordonné les données, les trier, c'est la fonction sort :
$cat 2701-0.txt | /home/laure.gajetti-dsti/map.py | sort -k1 -n
-k1 car nous somme sur la première cles de valeur.

Ensuite on crée la deuxieme partie : le reducer : fichier reduce.py :
$vi reduce.py
Ajout du script :
#!/usr/bin/env python
"""reduce.py"""

from operator import itemgetter
import sys

current_word = None
current_count = 0
word = None

# input comes from STDIN
for line in sys.stdin:
    # remove leading and trailing whitespace
    line = line.strip()

    # parse the input we got from mapper.py
    word, count = line.split('\t', 1)

    # convert count (currently a string) to int
    try:
        count = int(count)
    except ValueError:
        # count was not a number, so silently
        # ignore/discard this line
        continue

    # this IF-switch only works because Hadoop sorts map output
    # by key (here: word) before it is passed to the reducer
    if current_word == word:
        current_count += count
    else:
        if current_word:
            # write result to STDOUT
            print '%s\t%s' % (current_word, current_count)
        current_count = count
        current_word = word

# do not forget to output the last word if needed!
if current_word == word:
    print '%s\t%s' % (current_word, current_count)

Enfin on peut faire tourner le job sur yarn :
yarn jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar \
	-file /home/michael/map.py \
	-mapper /home/laure.gajetti-dsti/map.py \
	-file /home/laure.gajetti-dsti//reduce.py \
	-reducer /home/laure.gajetti-dsti//reduce.py \
	-input /user/laure.gajetti-dsti//raw/2701-0.txt \
	-output /user/laure.gajetti-dsti//python-output
  
  Comme vous pouvez le voir les résultats vont se trouver dans le dossier nommé python-output sur la partition 
  hdfs (path = /user/...)
  Vous venez d'executer un job complet de map-reduce.
  Le resultat pour se fichier est 13851
  
  On aurait également pu l'executer en local : 
  $ cat 2701-0.txt | /home/laure.gajetti-dsti/map.py | sort -k1 -n | /home/laure.gajetti-dsti/reduce.py | sort -k2 -n
  
  Et heureusement le resultat est le même : 13851
  
